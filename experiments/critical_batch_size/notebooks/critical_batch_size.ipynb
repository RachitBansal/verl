{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critical Batch Size in RLVR\n",
    "\n",
    "Analysis notebook for the CBS experiments. Pulls wandb logs, computes S(B) and E(B),\n",
    "fits the McCandlish model, and produces publication-quality plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from scipy.optimize import curve_fit\n",
    "from collections import defaultdict\n",
    "import wandb\n",
    "\n",
    "matplotlib.rcParams.update({\n",
    "    \"font.size\": 13,\n",
    "    \"axes.labelsize\": 14,\n",
    "    \"axes.titlesize\": 15,\n",
    "    \"legend.fontsize\": 11,\n",
    "    \"xtick.labelsize\": 12,\n",
    "    \"ytick.labelsize\": 12,\n",
    "    \"figure.figsize\": (7, 5),\n",
    "    \"figure.dpi\": 150,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Experiment Data from Wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WANDB_ENTITY = \"harvardml\"\n",
    "WANDB_PROJECT = \"cbs_rlvr\"\n",
    "\n",
    "# Phase tags to load\n",
    "PHASE_TAGS = [\"p1\", \"p2a\", \"p2b\", \"p2c\", \"p4_math\", \"p4_rpp\"]\n",
    "\n",
    "api = wandb.Api()\n",
    "runs = api.runs(f\"{WANDB_ENTITY}/{WANDB_PROJECT}\")\n",
    "print(f\"Found {len(runs)} runs in {WANDB_ENTITY}/{WANDB_PROJECT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_experiment_name(name: str) -> dict:\n",
    "    \"\"\"Parse cbs_{phase}_np{n_prompts}_nr{n_rollouts} into components.\"\"\"\n",
    "    parts = name.split(\"_\")\n",
    "    result = {\"name\": name, \"phase\": None, \"n_prompts\": None, \"n_rollouts\": None}\n",
    "    for p in parts:\n",
    "        if p.startswith(\"np\"):\n",
    "            result[\"n_prompts\"] = int(p[2:])\n",
    "        elif p.startswith(\"nr\"):\n",
    "            result[\"n_rollouts\"] = int(p[2:])\n",
    "    # Phase is everything between 'cbs_' and '_np'\n",
    "    if \"_np\" in name and name.startswith(\"cbs_\"):\n",
    "        result[\"phase\"] = name.split(\"_np\")[0].replace(\"cbs_\", \"\")\n",
    "    if result[\"n_prompts\"] and result[\"n_rollouts\"]:\n",
    "        result[\"total_batch\"] = result[\"n_prompts\"] * result[\"n_rollouts\"]\n",
    "    return result\n",
    "\n",
    "\n",
    "def load_run_history(run, keys=None):\n",
    "    \"\"\"Load history DataFrame for a wandb run.\"\"\"\n",
    "    if keys is None:\n",
    "        keys = [\n",
    "            \"training/global_step\",\n",
    "            \"critic/score/mean\",\n",
    "            \"actor/entropy\",\n",
    "            \"perf/time_per_step\",\n",
    "            \"perf/throughput\",\n",
    "        ]\n",
    "        # Also grab all val-core metrics\n",
    "        keys.append(\"_step\")\n",
    "    hist = run.scan_history(keys=keys, page_size=10000)\n",
    "    return pd.DataFrame(list(hist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all runs and their histories\n",
    "all_runs = {}\n",
    "for run in runs:\n",
    "    meta = parse_experiment_name(run.name)\n",
    "    if meta[\"phase\"] is None:\n",
    "        continue\n",
    "    meta[\"run_id\"] = run.id\n",
    "    meta[\"state\"] = run.state\n",
    "\n",
    "    # Load full history including val metrics\n",
    "    hist = pd.DataFrame(list(run.scan_history(page_size=10000)))\n",
    "    meta[\"history\"] = hist\n",
    "    all_runs[run.name] = meta\n",
    "    print(f\"  Loaded {run.name}: {len(hist)} rows, state={run.state}\")\n",
    "\n",
    "print(f\"\\nTotal runs loaded: {len(all_runs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract S(B) and E(B)\n",
    "\n",
    "For each run, find the step at which a target accuracy threshold is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_val_accuracy_columns(hist: pd.DataFrame) -> list[str]:\n",
    "    \"\"\"Find val-core accuracy columns in the history DataFrame.\"\"\"\n",
    "    return [c for c in hist.columns if \"val-core\" in c and \"mean@\" in c]\n",
    "\n",
    "\n",
    "def get_accuracy_at_step(hist: pd.DataFrame, acc_col: str) -> pd.Series:\n",
    "    \"\"\"Extract (step, accuracy) series from history, forward-filling NaN.\"\"\"\n",
    "    step_col = \"training/global_step\"\n",
    "    if step_col not in hist.columns or acc_col not in hist.columns:\n",
    "        return pd.Series(dtype=float)\n",
    "    df = hist[[step_col, acc_col]].dropna(subset=[acc_col]).copy()\n",
    "    df = df.rename(columns={step_col: \"step\", acc_col: \"accuracy\"})\n",
    "    return df.set_index(\"step\")[\"accuracy\"]\n",
    "\n",
    "\n",
    "def steps_to_threshold(acc_series: pd.Series, threshold: float) -> int | None:\n",
    "    \"\"\"Find the first step where accuracy >= threshold.\"\"\"\n",
    "    above = acc_series[acc_series >= threshold]\n",
    "    if len(above) == 0:\n",
    "        return None\n",
    "    return int(above.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sb_eb(runs_dict: dict, phase: str, acc_col: str | None = None,\n",
    "                  thresholds: list[float] | None = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute S(B) and E(B) for runs in a given phase.\n",
    "\n",
    "    Returns DataFrame with columns:\n",
    "      n_prompts, n_rollouts, total_batch, threshold, S_B, E_B\n",
    "    \"\"\"\n",
    "    if thresholds is None:\n",
    "        thresholds = [0.3, 0.4, 0.5, 0.6, 0.65, 0.7]\n",
    "\n",
    "    rows = []\n",
    "    for name, meta in runs_dict.items():\n",
    "        if meta[\"phase\"] != phase:\n",
    "            continue\n",
    "        hist = meta[\"history\"]\n",
    "        if hist.empty:\n",
    "            continue\n",
    "\n",
    "        # Auto-detect accuracy column if not specified\n",
    "        if acc_col is None:\n",
    "            val_cols = find_val_accuracy_columns(hist)\n",
    "            if not val_cols:\n",
    "                continue\n",
    "            # Pick the GSM8K accuracy column (prefer it over MATH)\n",
    "            gsm_cols = [c for c in val_cols if \"gsm\" in c.lower()]\n",
    "            col = gsm_cols[0] if gsm_cols else val_cols[0]\n",
    "        else:\n",
    "            col = acc_col\n",
    "\n",
    "        acc = get_accuracy_at_step(hist, col)\n",
    "        if acc.empty:\n",
    "            continue\n",
    "\n",
    "        for thresh in thresholds:\n",
    "            s_b = steps_to_threshold(acc, thresh)\n",
    "            rows.append({\n",
    "                \"n_prompts\": meta[\"n_prompts\"],\n",
    "                \"n_rollouts\": meta[\"n_rollouts\"],\n",
    "                \"total_batch\": meta[\"total_batch\"],\n",
    "                \"threshold\": thresh,\n",
    "                \"S_B\": s_b,\n",
    "                \"E_B\": s_b * meta[\"total_batch\"] if s_b is not None else None,\n",
    "                \"acc_col\": col,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute S(B), E(B) for Phase 1\n",
    "sb_eb_p1 = compute_sb_eb(all_runs, phase=\"p1\")\n",
    "print(\"Phase 1 S(B)/E(B):\")\n",
    "sb_eb_p1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fit the McCandlish Model\n",
    "\n",
    "$$S(B) = S_{\\min} \\cdot \\left(1 + \\frac{B_{\\text{noise}}}{B}\\right)$$\n",
    "\n",
    "$$E(B) = E_{\\min} \\cdot \\left(1 + \\frac{B}{B_{\\text{noise}}}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mccandlish_S(B, S_min, B_noise):\n",
    "    return S_min * (1 + B_noise / B)\n",
    "\n",
    "\n",
    "def mccandlish_E(B, E_min, B_noise):\n",
    "    return E_min * (1 + B / B_noise)\n",
    "\n",
    "\n",
    "def fit_cbs(df: pd.DataFrame, threshold: float, batch_col: str = \"total_batch\"):\n",
    "    \"\"\"\n",
    "    Fit B_noise from S(B) data at a given accuracy threshold.\n",
    "\n",
    "    Returns dict with S_min, B_noise, and goodness-of-fit info.\n",
    "    \"\"\"\n",
    "    sub = df[(df[\"threshold\"] == threshold) & df[\"S_B\"].notna()].copy()\n",
    "    if len(sub) < 3:\n",
    "        return None\n",
    "\n",
    "    B_vals = sub[batch_col].values.astype(float)\n",
    "    S_vals = sub[\"S_B\"].values.astype(float)\n",
    "\n",
    "    try:\n",
    "        popt, pcov = curve_fit(\n",
    "            mccandlish_S, B_vals, S_vals,\n",
    "            p0=[S_vals.min(), B_vals[len(B_vals) // 2]],\n",
    "            bounds=([0, 0], [np.inf, np.inf]),\n",
    "            maxfev=10000,\n",
    "        )\n",
    "        S_min_fit, B_noise_fit = popt\n",
    "        S_pred = mccandlish_S(B_vals, *popt)\n",
    "        ss_res = np.sum((S_vals - S_pred) ** 2)\n",
    "        ss_tot = np.sum((S_vals - S_vals.mean()) ** 2)\n",
    "        r_squared = 1 - ss_res / ss_tot if ss_tot > 0 else 0\n",
    "\n",
    "        return {\n",
    "            \"threshold\": threshold,\n",
    "            \"S_min\": S_min_fit,\n",
    "            \"B_noise\": B_noise_fit,\n",
    "            \"R2\": r_squared,\n",
    "            \"B_vals\": B_vals,\n",
    "            \"S_vals\": S_vals,\n",
    "        }\n",
    "    except RuntimeError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit CBS for each threshold\n",
    "thresholds = [0.3, 0.4, 0.5, 0.6, 0.65, 0.7]\n",
    "fits = {}\n",
    "for t in thresholds:\n",
    "    result = fit_cbs(sb_eb_p1, t)\n",
    "    if result is not None:\n",
    "        fits[t] = result\n",
    "        print(f\"Threshold {t:.0%}: B_noise={result['B_noise']:.0f}, \"\n",
    "              f\"S_min={result['S_min']:.1f}, R²={result['R2']:.4f}\")\n",
    "    else:\n",
    "        print(f\"Threshold {t:.0%}: insufficient data to fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sb_eb(sb_eb_df: pd.DataFrame, fits: dict, title_suffix: str = \"\"):\n",
    "    \"\"\"\n",
    "    Plot S(B) and E(B) with fitted curves.\n",
    "    Produces the classic CBS visualization.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5.5))\n",
    "\n",
    "    cmap = plt.cm.viridis\n",
    "    thresholds_with_data = sorted(fits.keys())\n",
    "    colors = {t: cmap(i / max(len(thresholds_with_data) - 1, 1))\n",
    "              for i, t in enumerate(thresholds_with_data)}\n",
    "\n",
    "    for thresh, fit in fits.items():\n",
    "        c = colors[thresh]\n",
    "        B = fit[\"B_vals\"]\n",
    "        S = fit[\"S_vals\"]\n",
    "\n",
    "        # S(B) plot\n",
    "        axes[0].scatter(B, S, color=c, s=60, zorder=5)\n",
    "        B_smooth = np.geomspace(B.min() * 0.5, B.max() * 2, 200)\n",
    "        S_smooth = mccandlish_S(B_smooth, fit[\"S_min\"], fit[\"B_noise\"])\n",
    "        axes[0].plot(B_smooth, S_smooth, color=c, alpha=0.7,\n",
    "                     label=f\"acc={thresh:.0%} (B*={fit['B_noise']:.0f})\")\n",
    "        axes[0].axvline(fit[\"B_noise\"], color=c, ls=\":\", alpha=0.4)\n",
    "\n",
    "        # E(B) plot\n",
    "        E = S * B\n",
    "        axes[1].scatter(B, E, color=c, s=60, zorder=5)\n",
    "        E_min = fit[\"S_min\"] * fit[\"B_noise\"]\n",
    "        E_smooth = mccandlish_E(B_smooth, E_min, fit[\"B_noise\"])\n",
    "        axes[1].plot(B_smooth, E_smooth, color=c, alpha=0.7,\n",
    "                     label=f\"acc={thresh:.0%}\")\n",
    "        axes[1].axvline(fit[\"B_noise\"], color=c, ls=\":\", alpha=0.4)\n",
    "\n",
    "    for ax in axes:\n",
    "        ax.set_xscale(\"log\", base=2)\n",
    "        ax.set_yscale(\"log\", base=2)\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "    axes[0].set_xlabel(\"Batch size B (total samples/step)\")\n",
    "    axes[0].set_ylabel(\"Steps to target S(B)\")\n",
    "    axes[0].set_title(f\"S(B): Steps to target{title_suffix}\")\n",
    "\n",
    "    axes[1].set_xlabel(\"Batch size B (total samples/step)\")\n",
    "    axes[1].set_ylabel(\"Total samples E(B) = B·S(B)\")\n",
    "    axes[1].set_title(f\"E(B): Total samples to target{title_suffix}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1 CBS plot\n",
    "if fits:\n",
    "    fig = plot_sb_eb(sb_eb_p1, fits, title_suffix=\" (Phase 1: vary n_prompts)\")\n",
    "    fig.savefig(\"cbs_phase1_sb_eb.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No fits available yet. Run Phase 1 experiments first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training Curves: Accuracy vs Steps and vs Total Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(runs_dict: dict, phase: str, metric_col: str | None = None):\n",
    "    \"\"\"\n",
    "    Plot training curves for all runs in a phase.\n",
    "    Left: accuracy vs steps. Right: accuracy vs total samples processed.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5.5))\n",
    "\n",
    "    phase_runs = {k: v for k, v in runs_dict.items() if v[\"phase\"] == phase}\n",
    "    if not phase_runs:\n",
    "        print(f\"No runs found for phase {phase}\")\n",
    "        return\n",
    "\n",
    "    sorted_runs = sorted(phase_runs.values(), key=lambda x: x[\"total_batch\"])\n",
    "    cmap = plt.cm.plasma\n",
    "    n = len(sorted_runs)\n",
    "\n",
    "    for i, meta in enumerate(sorted_runs):\n",
    "        hist = meta[\"history\"]\n",
    "        if hist.empty:\n",
    "            continue\n",
    "\n",
    "        if metric_col is None:\n",
    "            val_cols = find_val_accuracy_columns(hist)\n",
    "            gsm_cols = [c for c in val_cols if \"gsm\" in c.lower()]\n",
    "            col = gsm_cols[0] if gsm_cols else (val_cols[0] if val_cols else None)\n",
    "        else:\n",
    "            col = metric_col\n",
    "\n",
    "        if col is None or col not in hist.columns:\n",
    "            continue\n",
    "\n",
    "        step_col = \"training/global_step\"\n",
    "        df = hist[[step_col, col]].dropna(subset=[col])\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        steps = df[step_col].values\n",
    "        acc = df[col].values\n",
    "        total_samples = steps * meta[\"total_batch\"]\n",
    "        color = cmap(i / max(n - 1, 1))\n",
    "        label = f\"B={meta['total_batch']} (np={meta['n_prompts']},nr={meta['n_rollouts']})\"\n",
    "\n",
    "        axes[0].plot(steps, acc, color=color, label=label, marker=\"o\", ms=3)\n",
    "        axes[1].plot(total_samples, acc, color=color, label=label, marker=\"o\", ms=3)\n",
    "\n",
    "    axes[0].set_xlabel(\"Training steps\")\n",
    "    axes[0].set_ylabel(\"Accuracy\")\n",
    "    axes[0].set_title(f\"Accuracy vs Steps ({phase})\")\n",
    "    axes[0].legend(fontsize=8)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[1].set_xlabel(\"Total samples processed\")\n",
    "    axes[1].set_ylabel(\"Accuracy\")\n",
    "    axes[1].set_title(f\"Accuracy vs Total Samples ({phase})\")\n",
    "    axes[1].legend(fontsize=8)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_training_curves(all_runs, \"p1\")\n",
    "if fig:\n",
    "    fig.savefig(\"cbs_phase1_training_curves.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Two-Axis Decomposition (Phase 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2B: Fix n_prompts, vary n_rollouts\n",
    "sb_eb_p2b = compute_sb_eb(all_runs, phase=\"p2b\")\n",
    "\n",
    "fits_p2b = {}\n",
    "for t in thresholds:\n",
    "    result = fit_cbs(sb_eb_p2b, t, batch_col=\"total_batch\")\n",
    "    if result is not None:\n",
    "        fits_p2b[t] = result\n",
    "\n",
    "if fits_p2b:\n",
    "    fig = plot_sb_eb(sb_eb_p2b, fits_p2b, title_suffix=\" (Phase 2B: vary n_rollouts)\")\n",
    "    fig.savefig(\"cbs_phase2b_sb_eb.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2C: Iso-batch decomposition\n",
    "# All runs have total_batch=2048 but different (n_prompts, n_rollouts) splits\n",
    "\n",
    "def plot_iso_batch(runs_dict: dict, phase: str = \"p2c\"):\n",
    "    \"\"\"Plot accuracy vs steps for iso-batch experiments, colored by n_rollouts.\"\"\"\n",
    "    phase_runs = {k: v for k, v in runs_dict.items() if v[\"phase\"] == phase}\n",
    "    if not phase_runs:\n",
    "        print(f\"No runs for phase {phase}\")\n",
    "        return\n",
    "\n",
    "    sorted_runs = sorted(phase_runs.values(), key=lambda x: x[\"n_rollouts\"])\n",
    "    cmap = plt.cm.coolwarm\n",
    "    n = len(sorted_runs)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5.5))\n",
    "\n",
    "    for i, meta in enumerate(sorted_runs):\n",
    "        hist = meta[\"history\"]\n",
    "        if hist.empty:\n",
    "            continue\n",
    "        val_cols = find_val_accuracy_columns(hist)\n",
    "        gsm_cols = [c for c in val_cols if \"gsm\" in c.lower()]\n",
    "        col = gsm_cols[0] if gsm_cols else (val_cols[0] if val_cols else None)\n",
    "        if col is None:\n",
    "            continue\n",
    "\n",
    "        step_col = \"training/global_step\"\n",
    "        df = hist[[step_col, col]].dropna(subset=[col])\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        color = cmap(i / max(n - 1, 1))\n",
    "        label = f\"np={meta['n_prompts']}, nr={meta['n_rollouts']}\"\n",
    "        ax.plot(df[step_col], df[col], color=color, label=label, marker=\"o\", ms=4)\n",
    "\n",
    "    ax.set_xlabel(\"Training steps\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_title(f\"Iso-batch (B=2048): Prompt diversity vs Rollout diversity\")\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "fig = plot_iso_batch(all_runs, \"p2c\")\n",
    "if fig:\n",
    "    fig.savefig(\"cbs_phase2c_iso_batch.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Gradient Noise Scale Analysis (Phase 3)\n",
    "\n",
    "If gradient noise metrics were logged during training, analyze them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_gradient_noise(runs_dict: dict, phase: str = \"p1\"):\n",
    "    \"\"\"Plot estimated B_noise over training steps.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5.5))\n",
    "\n",
    "    phase_runs = {k: v for k, v in runs_dict.items() if v[\"phase\"] == phase}\n",
    "    sorted_runs = sorted(phase_runs.values(), key=lambda x: x[\"total_batch\"])\n",
    "    cmap = plt.cm.plasma\n",
    "    n = len(sorted_runs)\n",
    "\n",
    "    for i, meta in enumerate(sorted_runs):\n",
    "        hist = meta[\"history\"]\n",
    "        if hist.empty:\n",
    "            continue\n",
    "\n",
    "        step_col = \"training/global_step\"\n",
    "        noise_col = \"grad_noise/B_noise_estimate\"\n",
    "        norm_col = \"grad_noise/grad_norm\"\n",
    "\n",
    "        if noise_col not in hist.columns:\n",
    "            continue\n",
    "\n",
    "        df = hist[[step_col, noise_col, norm_col]].dropna(subset=[noise_col])\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        color = cmap(i / max(n - 1, 1))\n",
    "        label = f\"B={meta['total_batch']}\"\n",
    "\n",
    "        axes[0].plot(df[step_col], df[noise_col], color=color, label=label, alpha=0.8)\n",
    "        axes[1].plot(df[step_col], df[norm_col], color=color, label=label, alpha=0.8)\n",
    "\n",
    "    axes[0].set_xlabel(\"Training step\")\n",
    "    axes[0].set_ylabel(\"Estimated B_noise\")\n",
    "    axes[0].set_title(\"Gradient noise scale over training\")\n",
    "    axes[0].legend(fontsize=8)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[1].set_xlabel(\"Training step\")\n",
    "    axes[1].set_ylabel(\"Gradient norm\")\n",
    "    axes[1].set_title(\"Gradient norm over training\")\n",
    "    axes[1].legend(fontsize=8)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "fig = plot_gradient_noise(all_runs, \"p1\")\n",
    "if fig:\n",
    "    fig.savefig(\"cbs_grad_noise.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No gradient noise data available. Enable grad noise measurement in training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. CBS Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cbs_summary(phases: dict[str, dict]) -> pd.DataFrame:\n",
    "    \"\"\"Create a summary table of CBS estimates across phases and thresholds.\"\"\"\n",
    "    rows = []\n",
    "    for phase_name, phase_fits in phases.items():\n",
    "        for thresh, fit in phase_fits.items():\n",
    "            rows.append({\n",
    "                \"Phase\": phase_name,\n",
    "                \"Target Accuracy\": f\"{thresh:.0%}\",\n",
    "                \"B_noise (CBS)\": f\"{fit['B_noise']:.0f}\",\n",
    "                \"S_min\": f\"{fit['S_min']:.1f}\",\n",
    "                \"R²\": f\"{fit['R2']:.4f}\",\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "all_phase_fits = {\"Phase 1 (vary n_prompts)\": fits}\n",
    "if fits_p2b:\n",
    "    all_phase_fits[\"Phase 2B (vary n_rollouts)\"] = fits_p2b\n",
    "\n",
    "summary = make_cbs_summary(all_phase_fits)\n",
    "print(summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Throughput Analysis\n",
    "\n",
    "Plot wall-clock time efficiency to complement the sample efficiency analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wall_clock_efficiency(runs_dict: dict, phase: str, acc_col: str | None = None,\n",
    "                               threshold: float = 0.5):\n",
    "    \"\"\"\n",
    "    For each batch size, estimate wall-clock time to reach threshold.\n",
    "    Plot: time-to-target vs batch size (shows if scaling is efficient).\n",
    "    \"\"\"\n",
    "    phase_runs = {k: v for k, v in runs_dict.items() if v[\"phase\"] == phase}\n",
    "    results = []\n",
    "\n",
    "    for name, meta in phase_runs.items():\n",
    "        hist = meta[\"history\"]\n",
    "        if hist.empty:\n",
    "            continue\n",
    "\n",
    "        if acc_col is None:\n",
    "            val_cols = find_val_accuracy_columns(hist)\n",
    "            gsm_cols = [c for c in val_cols if \"gsm\" in c.lower()]\n",
    "            col = gsm_cols[0] if gsm_cols else (val_cols[0] if val_cols else None)\n",
    "        else:\n",
    "            col = acc_col\n",
    "        if col is None:\n",
    "            continue\n",
    "\n",
    "        time_col = \"perf/time_per_step\"\n",
    "        step_col = \"training/global_step\"\n",
    "        if time_col not in hist.columns:\n",
    "            continue\n",
    "\n",
    "        acc_series = get_accuracy_at_step(hist, col)\n",
    "        s_b = steps_to_threshold(acc_series, threshold)\n",
    "        if s_b is None:\n",
    "            continue\n",
    "\n",
    "        avg_time_per_step = hist[time_col].dropna().mean()\n",
    "        total_wall_time = s_b * avg_time_per_step\n",
    "\n",
    "        results.append({\n",
    "            \"total_batch\": meta[\"total_batch\"],\n",
    "            \"n_prompts\": meta[\"n_prompts\"],\n",
    "            \"n_rollouts\": meta[\"n_rollouts\"],\n",
    "            \"steps\": s_b,\n",
    "            \"avg_step_time_s\": avg_time_per_step,\n",
    "            \"wall_time_h\": total_wall_time / 3600,\n",
    "        })\n",
    "\n",
    "    if not results:\n",
    "        print(\"No wall-clock data available\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(results).sort_values(\"total_batch\")\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5.5))\n",
    "\n",
    "    axes[0].plot(df[\"total_batch\"], df[\"wall_time_h\"], \"o-\", color=\"steelblue\", ms=8)\n",
    "    axes[0].set_xscale(\"log\", base=2)\n",
    "    axes[0].set_xlabel(\"Batch size B\")\n",
    "    axes[0].set_ylabel(\"Wall-clock time (hours)\")\n",
    "    axes[0].set_title(f\"Wall-clock time to {threshold:.0%} accuracy\")\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "    axes[1].plot(df[\"total_batch\"], df[\"avg_step_time_s\"], \"o-\", color=\"coral\", ms=8)\n",
    "    axes[1].set_xscale(\"log\", base=2)\n",
    "    axes[1].set_xlabel(\"Batch size B\")\n",
    "    axes[1].set_ylabel(\"Avg time per step (seconds)\")\n",
    "    axes[1].set_title(\"Step time vs batch size\")\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "fig = plot_wall_clock_efficiency(all_runs, \"p1\", threshold=0.5)\n",
    "if fig:\n",
    "    fig.savefig(\"cbs_wall_clock.pdf\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
